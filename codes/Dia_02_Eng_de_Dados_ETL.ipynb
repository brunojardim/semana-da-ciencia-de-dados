{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "### Dia01: Processamento de Grande Volume de Dados \n* Engine PySpark (Python API for Spark)\n* Processamento em Mem\u00f3ria"}, {"metadata": {}, "cell_type": "markdown", "source": "### Cen\u00e1rio: \nTemos 3 tabelas e desejamos fazer um ETL para gerar uma tabela anal\u00edtica (ABT) na granularidade do cliente (client_id):\n    * clients: tabela contendo clientes \n    * loan: tabela contendo empr\u00e9stimos realizados pelos clientes\n    * payments: tabela contendo pagamentos realizados clientes"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Iniciando aplica\u00e7\u00e3o spark - Ambiente Turing Lab"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1571701187419_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-35-30-129.ec2.internal:20888/proxy/application_1571701187419_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-35-30-129.ec2.internal:8042/node/containerlogs/container_1571701187419_0001_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n<pyspark.sql.session.SparkSession object at 0x7fc8074dd190>", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Lendo tabela de clientes (arquivo csv guardado no lake)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_clients = spark.read.format(\n   \"com.databricks.spark.csv\").option(\n   \"header\", \"true\").option(\n   \"inferSchema\", \"true\").option(\n   \"delimiter\", ',').load(\n   's3://turing-bkt-treinamentos-etl/Exemplo/clients.csv')\nrdd_clients.count()", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "25", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Verificando Schema da tabela"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_clients.printSchema()", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "root\n |-- client_id: integer (nullable = true)\n |-- joined: timestamp (nullable = true)\n |-- income: integer (nullable = true)\n |-- credit_score: integer (nullable = true)", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Verificando 5 primeiras linhas da tabela"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_clients.show(5)", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "+---------+-------------------+------+------------+\n|client_id|             joined|income|credit_score|\n+---------+-------------------+------+------------+\n|    46109|2002-04-16 00:00:00|172677|         527|\n|    49545|2007-11-14 00:00:00|104564|         770|\n|    41480|2013-03-11 00:00:00|122607|         585|\n|    46180|2001-11-06 00:00:00| 43851|         562|\n|    25707|2006-10-06 00:00:00|211422|         621|\n+---------+-------------------+------+------------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Lendo tabela de empr\u00e9stimos realizados pelos clientes (arquivo csv guardado no lake)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan = spark.read.format(\n   \"com.databricks.spark.csv\").option(\n   \"header\", \"true\").option(\n   \"inferSchema\", \"true\").option(\n   \"delimiter\", ',').load(\n   's3://turing-bkt-treinamentos-etl/Exemplo/loans.csv')\nrdd_loan.count()", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "443", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan.printSchema()", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "root\n |-- client_id: integer (nullable = true)\n |-- loan_type: string (nullable = true)\n |-- loan_amount: integer (nullable = true)\n |-- repaid: integer (nullable = true)\n |-- loan_id: integer (nullable = true)\n |-- loan_start: timestamp (nullable = true)\n |-- loan_end: timestamp (nullable = true)\n |-- rate: double (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan.show()", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "+---------+---------+-----------+------+-------+-------------------+-------------------+----+\n|client_id|loan_type|loan_amount|repaid|loan_id|         loan_start|           loan_end|rate|\n+---------+---------+-----------+------+-------+-------------------+-------------------+----+\n|    46109|     home|      13672|     0|  10243|2002-04-16 00:00:00|2003-12-20 00:00:00|2.15|\n|    46109|   credit|       9794|     0|  10984|2003-10-21 00:00:00|2005-07-17 00:00:00|1.25|\n|    46109|     home|      12734|     1|  10990|2006-02-01 00:00:00|2007-07-05 00:00:00|0.68|\n|    46109|     cash|      12518|     1|  10596|2010-12-08 00:00:00|2013-05-05 00:00:00|1.24|\n|    46109|   credit|      14049|     1|  11415|2010-07-07 00:00:00|2012-05-21 00:00:00|3.13|\n|    46109|     home|       6935|     0|  11501|2006-09-17 00:00:00|2008-11-26 00:00:00|1.94|\n|    46109|     cash|       6177|     1|  11141|2007-03-12 00:00:00|2009-04-26 00:00:00|9.48|\n|    46109|     home|      12656|     0|  11658|2006-05-26 00:00:00|2007-10-15 00:00:00|4.14|\n|    46109|     home|      11062|     1|  11611|2012-09-12 00:00:00|2014-03-14 00:00:00|5.48|\n|    46109|    other|       4050|     1|  10828|2003-12-06 00:00:00|2005-08-19 00:00:00|4.26|\n|    46109|    other|       1618|     0|  11661|2006-08-28 00:00:00|2009-04-23 00:00:00|6.49|\n|    46109|     home|       8406|     0|  11259|2011-10-22 00:00:00|2013-06-11 00:00:00| 0.5|\n|    46109|     cash|       9057|     1|  10856|2005-06-17 00:00:00|2007-03-01 00:00:00|0.86|\n|    46109|   credit|       3524|     0|  11867|2005-09-18 00:00:00|2007-08-27 00:00:00|5.98|\n|    46109|    other|      10853|     0|  11961|2013-11-26 00:00:00|2015-08-06 00:00:00|2.82|\n|    46109|   credit|       7339|     1|  10328|2001-09-24 00:00:00|2003-08-31 00:00:00|1.29|\n|    46109|   credit|      11953|     1|  11307|2013-05-15 00:00:00|2015-03-15 00:00:00| 3.3|\n|    46109|    other|      10067|     1|  10422|2004-04-05 00:00:00|2006-10-13 00:00:00|3.12|\n|    46109|   credit|      12009|     0|  11424|2001-03-25 00:00:00|2003-10-04 00:00:00|0.79|\n|    46109|   credit|        559|     1|  10599|2008-02-15 00:00:00|2009-11-25 00:00:00|4.15|\n+---------+---------+-----------+------+-------+-------------------+-------------------+----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Lendo tabela de pagamentos realizados pelos clientes (arquivo csv guardado no lake)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_payments = spark.read.format(\n   \"com.databricks.spark.csv\").option(\n   \"header\", \"true\").option(\n   \"inferSchema\", \"true\").option(\n   \"delimiter\", ',').load(\n   's3://turing-bkt-treinamentos-etl/Exemplo/payments.csv')\nrdd_payments.count()", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "3456", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_payments.printSchema()", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "root\n |-- loan_id: integer (nullable = true)\n |-- payment_amount: integer (nullable = true)\n |-- payment_date: timestamp (nullable = true)\n |-- missed: integer (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_payments.show()", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "+-------+--------------+-------------------+------+\n|loan_id|payment_amount|       payment_date|missed|\n+-------+--------------+-------------------+------+\n|  10243|          2369|2002-05-31 00:00:00|     1|\n|  10243|          2439|2002-06-18 00:00:00|     1|\n|  10243|          2662|2002-06-29 00:00:00|     0|\n|  10243|          2268|2002-07-20 00:00:00|     0|\n|  10243|          2027|2002-07-31 00:00:00|     1|\n|  10243|          2243|2002-09-16 00:00:00|     1|\n|  10984|          1466|2003-12-29 00:00:00|     0|\n|  10984|          1887|2004-02-01 00:00:00|     1|\n|  10984|          1360|2004-03-09 00:00:00|     1|\n|  10984|          1350|2004-03-29 00:00:00|     0|\n|  10984|          1728|2004-05-03 00:00:00|     1|\n|  10990|          1981|2006-04-05 00:00:00|     0|\n|  10990|          2284|2006-04-27 00:00:00|     1|\n|  10990|          1304|2006-05-12 00:00:00|     0|\n|  10990|          2253|2006-06-05 00:00:00|     1|\n|  10990|          2453|2006-07-17 00:00:00|     0|\n|  10990|          1903|2006-07-30 00:00:00|     0|\n|  10596|          1612|2011-01-25 00:00:00|     0|\n|  10596|          1499|2011-03-09 00:00:00|     1|\n|  10596|          1414|2011-04-10 00:00:00|     1|\n+-------+--------------+-------------------+------+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Vamos fazer todo ETL via HIVE (Nos possibilita utilizar SQL)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Disponibilzar tabelas (RDDs em mem\u00f3ria para o Hive)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_clients.registerTempTable(\"clientes\")\nrdd_loan.registerTempTable(\"emprestimos\")\nrdd_payments.registerTempTable(\"pagamentos\")", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Vamos utilizar SQL para explorar os emprestimos feitos pelo cliente de id 46109"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\n             \"\"\"SELECT \n                    client_id,\n                    loan_type,                    \n                    cast(loan_start as date) as DT_INICIO,\n                    cast(loan_end as date) as DT_FIM,\n                    datediff(cast(loan_end as date),cast(loan_start as date)) as QT_DIAS_START_END,\n                    round(datediff(cast(loan_end as date),cast(loan_start as date))/30.5) as QT_MESES_START_END,\n                    round(datediff(cast(loan_end as date),cast(loan_start as date))/365) as QT_ANOS_START_END\n                FROM\n                    emprestimos \n                WHERE \n                    client_id = 46109 \n                order by cast(loan_start as date)    \n             \"\"\"\n         ).show()", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "+---------+---------+----------+----------+-----------------+------------------+-----------------+\n|client_id|loan_type| DT_INICIO|    DT_FIM|QT_DIAS_START_END|QT_MESES_START_END|QT_ANOS_START_END|\n+---------+---------+----------+----------+-----------------+------------------+-----------------+\n|    46109|   credit|2001-03-25|2003-10-04|              923|                30|              3.0|\n|    46109|   credit|2001-09-24|2003-08-31|              706|                23|              2.0|\n|    46109|     home|2002-04-16|2003-12-20|              613|                20|              2.0|\n|    46109|   credit|2003-10-21|2005-07-17|              635|                21|              2.0|\n|    46109|    other|2003-12-06|2005-08-19|              622|                20|              2.0|\n|    46109|    other|2004-04-05|2006-10-13|              921|                30|              3.0|\n|    46109|     cash|2005-06-17|2007-03-01|              622|                20|              2.0|\n|    46109|   credit|2005-09-18|2007-08-27|              708|                23|              2.0|\n|    46109|     home|2006-02-01|2007-07-05|              519|                17|              1.0|\n|    46109|     home|2006-05-26|2007-10-15|              507|                17|              1.0|\n|    46109|    other|2006-08-28|2009-04-23|              969|                32|              3.0|\n|    46109|     home|2006-09-17|2008-11-26|              801|                26|              2.0|\n|    46109|     cash|2007-03-12|2009-04-26|              776|                25|              2.0|\n|    46109|   credit|2008-02-15|2009-11-25|              649|                21|              2.0|\n|    46109|   credit|2010-07-07|2012-05-21|              684|                22|              2.0|\n|    46109|     cash|2010-12-08|2013-05-05|              879|                29|              2.0|\n|    46109|     home|2011-10-22|2013-06-11|              598|                20|              2.0|\n|    46109|     home|2012-09-12|2014-03-14|              548|                18|              2.0|\n|    46109|   credit|2013-05-15|2015-03-15|              669|                22|              2.0|\n|    46109|    other|2013-11-26|2015-08-06|              618|                20|              2.0|\n+---------+---------+----------+----------+-----------------+------------------+-----------------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Quest\u00e3o 01) Quais s\u00e3o e quantos tipos de emprestimos diferentes existem na tabela de emprestimos ?"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\n             \"\"\"SELECT \n                    loan_type as TP_EMPRESTIMO, \n                    count(*) as QTD_EMPRESTIMOS\n                FROM\n                    emprestimos \n                group by loan_type\n             \"\"\"\n         ).show(100)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "+-------------+---------------+\n|TP_EMPRESTIMO|QTD_EMPRESTIMOS|\n+-------------+---------------+\n|         cash|            108|\n|        other|            107|\n|         home|            121|\n|       credit|            107|\n+-------------+---------------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Vamos trazer as informa\u00e7\u00f5es de pagamentos para a tabela de empr\u00e9stimos"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan_payments = spark.sql(\n                             \"\"\"SELECT \n                                    a.client_id,\n                                    a.loan_id,\n                                    a.loan_type,\n                                    a.loan_amount,\n                                    a.repaid,\n                                    a.rate, \n                                    datediff(cast(a.loan_end as date),cast(a.loan_start as date)) as QT_DIAS_START_END,\n                                    datediff(cast(b.payment_date as date),cast(a.loan_start as date)) as QT_DIAS_START_PAYMENT,\n                                    b.payment_amount,\n                                    b.missed\n                                FROM\n                                    emprestimos as a\n                                LEFT JOIN\n                                    pagamentos as b\n                                ON a.loan_id = b.loan_id\n                             \"\"\"\n                         )\nrdd_loan_payments.registerTempTable(\"loan_payments\")\nrdd_loan_payments.count()", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "3456", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan_payments.show()", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "+---------+-------+---------+-----------+------+----+-----------------+---------------------+--------------+------+\n|client_id|loan_id|loan_type|loan_amount|repaid|rate|QT_DIAS_START_END|QT_DIAS_START_PAYMENT|payment_amount|missed|\n+---------+-------+---------+-----------+------+----+-----------------+---------------------+--------------+------+\n|    46109|  10243|     home|      13672|     0|2.15|              613|                  153|          2243|     1|\n|    46109|  10243|     home|      13672|     0|2.15|              613|                  106|          2027|     1|\n|    46109|  10243|     home|      13672|     0|2.15|              613|                   95|          2268|     0|\n|    46109|  10243|     home|      13672|     0|2.15|              613|                   74|          2662|     0|\n|    46109|  10243|     home|      13672|     0|2.15|              613|                   63|          2439|     1|\n|    46109|  10243|     home|      13672|     0|2.15|              613|                   45|          2369|     1|\n|    46109|  10984|   credit|       9794|     0|1.25|              635|                  195|          1728|     1|\n|    46109|  10984|   credit|       9794|     0|1.25|              635|                  160|          1350|     0|\n|    46109|  10984|   credit|       9794|     0|1.25|              635|                  140|          1360|     1|\n|    46109|  10984|   credit|       9794|     0|1.25|              635|                  103|          1887|     1|\n|    46109|  10984|   credit|       9794|     0|1.25|              635|                   69|          1466|     0|\n|    46109|  10990|     home|      12734|     1|0.68|              519|                  179|          1903|     0|\n|    46109|  10990|     home|      12734|     1|0.68|              519|                  166|          2453|     0|\n|    46109|  10990|     home|      12734|     1|0.68|              519|                  124|          2253|     1|\n|    46109|  10990|     home|      12734|     1|0.68|              519|                  100|          1304|     0|\n|    46109|  10990|     home|      12734|     1|0.68|              519|                   85|          2284|     1|\n|    46109|  10990|     home|      12734|     1|0.68|              519|                   63|          1981|     0|\n|    46109|  10596|     cash|      12518|     1|1.24|              879|                  179|          1904|     1|\n|    46109|  10596|     cash|      12518|     1|1.24|              879|                  138|          1252|     1|\n|    46109|  10596|     cash|      12518|     1|1.24|              879|                  123|          1414|     1|\n+---------+-------+---------+-----------+------+----+-----------------+---------------------+--------------+------+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Agregar a tabela (rdd_loan_payments) de emprestimos e pagamentos para que fique na granularidade do cliente"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan_payments_agg = spark.sql(\n                             \"\"\"SELECT\n                                    client_id,\n                                    sum(case when loan_type = 'home' then  1 else 0 end) as QT_EMP_HOME,\n                                    sum(case when loan_type = 'credit' then  1 else 0 end) as QT_EMP_CRED,\n                                    sum(case when loan_type = 'cash' then  1 else 0 end) as QT_EMP_CASH,\n                                    sum(case when loan_type = 'other' then  1 else 0 end) as QT_EMP_OTHER,\n                                    mean(loan_amount) as mean_loan_amount,\n                                    max(loan_amount) as max_loan_amount,\n                                    min(loan_amount) as min_loan_amount,\n                                    mean(payment_amount) as mean_payment_amount,\n                                    max(payment_amount) as max_payment_amount,\n                                    min(payment_amount) as min_payment_amount, \n                                    max(QT_DIAS_START_PAYMENT) as MAX_QT_DIAS_START_PAYMENT,\n                                    mean(missed) as mean_missed,\n                                    mean(repaid) as mean_repaid,\n                                    mean(rate) as mean_rate,\n                                    max(QT_DIAS_START_END) as MAX_QT_DIAS_START_END                                    \n                                FROM\n                                    loan_payments \n                                GROUP BY\n                                    client_id\n                             \"\"\"\n                         )\nrdd_loan_payments_agg.registerTempTable(\"loan_payments_agg\")\nrdd_loan_payments_agg.count()", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "25", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_loan_payments_agg.printSchema()", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "root\n |-- client_id: integer (nullable = true)\n |-- QT_EMP_HOME: long (nullable = true)\n |-- QT_EMP_CRED: long (nullable = true)\n |-- QT_EMP_CASH: long (nullable = true)\n |-- QT_EMP_OTHER: long (nullable = true)\n |-- mean_loan_amount: double (nullable = true)\n |-- max_loan_amount: integer (nullable = true)\n |-- min_loan_amount: integer (nullable = true)\n |-- mean_payment_amount: double (nullable = true)\n |-- max_payment_amount: integer (nullable = true)\n |-- min_payment_amount: integer (nullable = true)\n |-- MAX_QT_DIAS_START_PAYMENT: integer (nullable = true)\n |-- mean_missed: double (nullable = true)\n |-- mean_repaid: double (nullable = true)\n |-- mean_rate: double (nullable = true)\n |-- MAX_QT_DIAS_START_END: integer (nullable = true)", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Trazer as informa\u00e7\u00f5es de empr\u00e9stimos e pagamentos para a tabela de clientes (apenas algumas variaveis como exemplo)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Criando variavel temporal de referencia atual\n\nimport datetime\nimport time\n\n# DEslocando 3 horas devido ao fuso hor\u00e1rio entre Brasil e EUA\nnow = datetime.datetime.now() + datetime.timedelta(0, 0, 0, 0, 0, -3)\nanomesdia = now.strftime(\"%Y%m%d\")\ntimestpref = now.strftime('%Y-%m-%dT%H:%M:%S')\n\n\nprint('Data de referencia (AAAAMMDD): ',anomesdia)", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "('Data de referencia (AAAAMMDD): ', '20191021')", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_final = spark.sql(\n                             \"\"\"SELECT\n                                    a.client_id as PK_ID,\n                                    a.credit_score as VL_SCORE,\n                                    a.income as VL_RENDA,\n                                    datediff(cast('{}' as date),cast(a.joined as date)) as QT_DIAS_JOINED_NOW,\n                                    b.QT_EMP_HOME,\n                                    b.QT_EMP_CRED,\n                                    round(b.mean_missed,2) as VL_MED_MISSED,\n                                    round(b.mean_repaid,2) as VL_MED_REPAID,\n                                    {} as PK_DATREF,\n                                    '{}' as PK_DATPROC\n                                FROM\n                                    clientes as a\n                                LEFT JOIN\n                                    loan_payments_agg as b\n                                ON a.client_id = b.client_id\n                             \"\"\".format(now,anomesdia,timestpref)\n                         )\nrdd_final.registerTempTable(\"rdd_final\")\nrdd_final.count()", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "25", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_final.show()", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "+-----+--------+--------+------------------+-----------+-----------+-------------+-------------+---------+-------------------+\n|PK_ID|VL_SCORE|VL_RENDA|QT_DIAS_JOINED_NOW|QT_EMP_HOME|QT_EMP_CRED|VL_MED_MISSED|VL_MED_REPAID|PK_DATREF|         PK_DATPROC|\n+-----+--------+--------+------------------+-----------+-----------+-------------+-------------+---------+-------------------+\n|35214|     696|   95849|              5918|         93|         21|         0.51|         0.39| 20191021|2019-10-21T21:14:35|\n|44601|     518|  156341|              5479|         47|         58|         0.46|         0.73| 20191021|2019-10-21T21:14:35|\n|26945|     806|  214516|              6903|         30|         43|         0.51|         0.34| 20191021|2019-10-21T21:14:35|\n|49545|     770|  104564|              4359|         49|         41|         0.58|         0.59| 20191021|2019-10-21T21:14:35|\n|49624|     800|   49036|              2634|         24|         35|         0.47|         0.62| 20191021|2019-10-21T21:14:35|\n|46109|     527|  172677|              6397|         40|         52|         0.48|         0.54| 20191021|2019-10-21T21:14:35|\n|42320|     563|  229481|              7116|         45|         18|         0.52|         0.58| 20191021|2019-10-21T21:14:35|\n|32726|     730|  235705|              4921|         37|         29|          0.5|          0.6| 20191021|2019-10-21T21:14:35|\n|29841|     523|   38354|              6274|         52|         42|         0.53|         0.56| 20191021|2019-10-21T21:14:35|\n|49068|     603|  128813|              5730|         25|         14|         0.49|         0.73| 20191021|2019-10-21T21:14:35|\n|41480|     585|  122607|              2415|         62|         34|         0.45|         0.47| 20191021|2019-10-21T21:14:35|\n|38537|     643|  127183|              6209|         17|         44|          0.5|         0.59| 20191021|2019-10-21T21:14:35|\n|32961|     714|  230341|              3849|         36|         37|         0.52|         0.42| 20191021|2019-10-21T21:14:35|\n|32885|     642|   58955|              6370|         35|         11|         0.51|         0.55| 20191021|2019-10-21T21:14:35|\n|25707|     621|  211422|              4763|         38|         52|         0.53|         0.47| 20191021|2019-10-21T21:14:35|\n|39505|     610|  153873|              2929|         37|         50|         0.48|         0.41| 20191021|2019-10-21T21:14:35|\n|39384|     617|  191204|              7064|         21|         49|         0.51|         0.58| 20191021|2019-10-21T21:14:35|\n|46958|     644|  225709|              3013|         23|         24|         0.45|         0.21| 20191021|2019-10-21T21:14:35|\n|26695|     680|  174532|              5533|         51|         27|         0.49|          0.4| 20191021|2019-10-21T21:14:35|\n|35089|     771|  131176|              3521|         54|         35|          0.5|         0.64| 20191021|2019-10-21T21:14:35|\n+-----+--------+--------+------------------+-----------+-----------+-------------+-------------+---------+-------------------+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_final.printSchema()", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "root\n |-- PK_ID: integer (nullable = true)\n |-- VL_SCORE: integer (nullable = true)\n |-- VL_RENDA: integer (nullable = true)\n |-- QT_DIAS_JOINED_NOW: integer (nullable = true)\n |-- QT_EMP_HOME: long (nullable = true)\n |-- QT_EMP_CRED: long (nullable = true)\n |-- VL_MED_MISSED: double (nullable = true)\n |-- VL_MED_REPAID: double (nullable = true)\n |-- PK_DATREF: integer (nullable = false)\n |-- PK_DATPROC: string (nullable = false)", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Formas de Salvar o resultado final do ETL\n    * CSV (particionado ou n\u00e3o particionado)\n    * PARQUET (particionado ou n\u00e3o particionado)\n    * HDFS \nRecomendado: Parquet particionado        "}, {"metadata": {}, "cell_type": "markdown", "source": "#### Salvando PARQUET n\u00e3o particionado no ambiente S3 \nLembre-se de trocar o nome da pasta de BrunoJ para o seu nome !!"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_final.write.parquet(\"s3://turing-bkt-treinamentos-etl/Alunos/Turma_20191021/ABT_CLI_EMP_PAG\",mode=\"overwrite\")", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Salvando PARQUET particionado por data (AAAAMMDD) no ambiente S3 \nCada nova data o c\u00f3digo cria automaticamente uma nova parti\u00e7\u00e3o com dados"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "nm_path_s3 = 's3://turing-bkt-treinamentos-etl/Alunos/Turma_20191021/PARTIT_ABT_CLI_EMP_PAG/'\nrdd_final.write.partitionBy('PK_DATREF').parquet(nm_path_s3, mode='append')", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Criando Schema HIVE para salvar tabelas resultantes do ETL"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\"create database treinamento\").show()", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "++\n||\n++\n++", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Salvando PARQUET particionado via HIVE"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_final.write.mode('append').partitionBy('PK_DATREF').saveAsTable(\"treinamento.PARTIT_ABT_CLI_EMP_PAG\")", "execution_count": 25, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.sql(\"show tables in treinamento\").show(10,False)", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "+-----------+----------------------+-----------+\n|database   |tableName             |isTemporary|\n+-----------+----------------------+-----------+\n|treinamento|partit_abt_cli_emp_pag|false      |\n|           |clientes              |true       |\n|           |emprestimos           |true       |\n|           |loan_payments         |true       |\n|           |loan_payments_agg     |true       |\n|           |pagamentos            |true       |\n|           |rdd_final             |true       |\n+-----------+----------------------+-----------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Para verificar os arquivos salvos no dirt\u00f3rio (Utilize prompt de comandos)\n\n* hdfs dfs -ls /user/spark/warehouse/treinamento.db\n\n* hdfs dfs -ls /user/spark/warehouse/treinamento.db/partit_abt_cli_emp_pag\n\n* hdfs dfs -ls /user/spark/warehouse/treinamento.db/partit_abt_cli_emp_pag/PK_DATREF=20190513"}, {"metadata": {}, "cell_type": "markdown", "source": "### Para limpar tabelas temporarias da memoria HIVE"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "spark.catalog.dropTempView(\"clientes\") \nspark.catalog.dropTempView(\"clients_dfm\") \nspark.catalog.dropTempView(\"emprestimos\") \nspark.catalog.dropTempView(\"loan_payments\") \nspark.catalog.dropTempView(\"loan_payments_agg\") \nspark.catalog.dropTempView(\"pagamentos\") \nspark.catalog.dropTempView(\"rdd_final\") \n\n\nspark.sql(\"show tables in treinamento\").show(10,False)", "execution_count": 27, "outputs": [{"output_type": "stream", "text": "+-----------+----------------------+-----------+\n|database   |tableName             |isTemporary|\n+-----------+----------------------+-----------+\n|treinamento|partit_abt_cli_emp_pag|false      |\n+-----------+----------------------+-----------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Lembrar que se o ETL for para gerar uma ABT de modelagem \u00e9 necess\u00e1rio fazer a amostra por aqui para reduzir tempo/esfor\u00e7o da m\u00e1quina quando na interface de Analytics"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Exemplo de amostragem \n* Gerar amostra de 10%, sem reposi\u00e7\u00e3o, da tabela de pagamentos"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd_payments_amt_10pct = rdd_payments.sample(False, 0.1, 12345)\nrdd_payments_amt_10pct.count()", "execution_count": 28, "outputs": [{"output_type": "stream", "text": "324", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}